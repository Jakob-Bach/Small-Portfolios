% Customized "beamer" class
% Template cloned from https://git.scc.kit.edu/i43/dokumentvorlagen/praesentationen/beamer | commit: 5c6fe51d431425942a350e8a439bb4cef08f0275 (2022-06-28)
% Due to unclear licensing, we do not provide the files "sdqbeamer.cls" and "logos/kitlogo_en_rgb.pdf" (need to be added manually)
\documentclass[en]{sdqbeamer}
% - remove animation roll-out: handout (general "beamer" option, not specific for this class)
% - layout options: 16:9 (default), 16:10, 4:3
% - footer font size options: bigfoot (default), smallfoot (KIT layout)
% - navigation bar options: navbarinline (default), navbarinfooter, navbarside, navbaroff, navbarkit (off + smallfoot)
% - language: de (default), en

\titleimage{title_image}

\grouplogo{}

\groupname{}
%\groupnamewidth{50mm} % default

\DeclareMathOperator*{\argmin}{arg\,min}

\title[A Comprehensive Study of k-Portfolios of Recent SAT Solvers]{A Comprehensive Study of k-Portfolios of Recent SAT Solvers} % [footer]{title slide}
\subtitle{SAT 2022 | Haifa, Israel}
\author[\underline{Jakob Bach}, Markus Iser, and Klemens Böhm]{\underline{Jakob Bach}, Markus Iser, and Klemens Böhm} % [footer]{title slide}
\date[2022-08-02]{August 2, 2022} % [footer]{title slide}

%\usepackage{amsmath} % mathematical symbols and equations; apparently pre-loaded
%\usepackage{amssymb} % mathematical symbols; apparently pre-loaded
\usepackage[style=numeric, backend=bibtex]{biblatex}  % original template uses "biber" as backend
%\usepackage{graphicx} % plots; apparently pre-loaded
%\usepackage{hyperref} % links and URLs; apparently pre-loaded
\usepackage{mathtools} % extends "amsmath"; provides \mathrlap
\usepackage{subcaption} % figures with multiple sub-figures; just used for \caption* here

\addbibresource{k-portfolio-presentation.bib}

\setlength{\leftmargini}{0.2cm} % change default identation (so items are left-aligned to boxes)
\setlength{\leftmarginii}{0.3cm} % 2nd level identation
\setlength{\leftmarginiii}{0.3cm} % 3rd level identation

\setbeamercovered{invisible} % use "transparent" to show later content of animated slide in gray
\setbeamertemplate{enumerate items}[default] % do not use the ugly colored circles

\begin{document}

\KITtitleframe

\section{Basics}

%\begin{frame}[t]{Problem Definition}
%	\begin{definition}[K-Portfolio-Problem]
%		Given a set of solvers $S = \{s_1, \dots, s_n\}$,
%		a scoring function $c: 2^S \rightarrow \mathbb{R}$,
%		and portfolio size $k \in \mathbb{N}$,
%		find a solver subset (= portfolio) $P$ of size $|P| = k$ with minimum cost: $\argmin\limits_{P \subseteq S, |P| = k} c(P)$
%	\end{definition}
%	%JB: term portfolio is a bit overloaded (see references in paper): set of algorithms 1) run in interleaved schedule, 2) with algorithm selector, or 3) run in parallel (with or wihthout exchanging information)
%	%JB: in our case, algorithm selector, though definition here is more general
%	\pause
%	\begin{itemize}
%		\item To express portfolio cost $c(P)$, we use
%		%JB: definition above allows for other scoring, but we focus on problem in following form
%		\begin{itemize}
%			\item Set of SAT instances $I = \{i_1, \dots, i_l\}$
%			\item Scoring function $c: I \times S \rightarrow \mathbb{R}$; here: PAR-2 score (penalized runtimes)
%			%JB: i.e., we use scoring as in SAT Competitions, whose datasets we analyze
%			%JB: in preliminary experiments, also two slightly different objectives: the number of unsolved instances and the PAR-2 score normalized for each instance -> general trends remained same
%			\item[$\rightarrow$] Determine score per instance and average this score over instances
%		\end{itemize}
%		\vspace{\baselineskip}
%		\pause
%		\item We analyze two methods for instance-specific solver selection from portfolio:
%		\begin{itemize}
%			\item Virtual Best Solver (VBS): oracle always selects best solver
%			%JB: mathenatically, we take min over solver runtimes on instance
%			\item Prediction model selects solver based on instance features
%		\end{itemize}
%	\end{itemize}
%\end{frame}

\begin{frame}[t]{Problem Definition}
	\begin{definition}[K-Portfolio Problem]
		\setlength{\leftmargini}{0.4cm} % further indentation for items in box (bullet should not touch border of box)
		Given
		%JB: all formal stuff in one box, therefore box somewhat large
		\pause
		\begin{itemize}
			\itemsep0em
			\item a set of solvers $S = \{s_1, \dots, s_n\}$,
			\pause
			\item a set of SAT instances $I = \{i_1, \dots, i_l\}$,
			\pause
			\item a scoring function $c: I \times S \rightarrow \mathbb{R}$ (here: PAR-2 score),
			%JB: scoring used in SAT Competitions
			%JB: in preliminary experiments, also two slightly different objectives: the number of unsolved instances and the PAR-2 score normalized for each instance -> general trends remained same
			\pause
			\item an instance-specific solver selector $m: I \rightarrow S$, and
			%JB: term portfolio is a bit overloaded (see references in paper): set of algorithms 1) run in interleaved schedule, 2) with algorithm selector, or 3) run in parallel (with or wihthout exchanging information); in our case, algorithm selector
			\pause
			\item a portfolio size $k \in \mathbb{N}$,
		\end{itemize}
		find a solver subset $P$ of size $k$ with minimum average cost: $\argmin\limits_{P \subseteq S, |P| = k} c(P,m) := \frac{1}{|I|} \cdot \sum\limits_{i \in I}{c(i,m(i))}$
	\end{definition}
	\pause
	\begin{itemize}
		\item We analyze two methods for instance-specific solver selection:
		\begin{itemize}
			\item Virtual Best Solver (VBS): Oracle always selects best solver
			%JB: theoretical K-Portfolio Problem, which we consider in portfolio search
			%JB: mathenatically, we take min() over solver runtimes on instance
			\pause
			\item Model-based: Prediction model selects solver based on instance features
			%JB: practical K-Portfolio Problem
			%JB: cost lower-bounded by VBS
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[t]{Related Work}
	\begin{itemize}
		\item Analyzing solver complementarity: Xu et al.~\cite{Xu:2012:EvalContribVBS}, Fr{\'e}chette et al.~\cite{frechette2016using}
		%JB: former analyze marginal contribution, latter analyze Shapley values
		%JB: both works use datasets with fixed solver set, don't vary k (focus is on individual solvers rather tha portfolios)
		%JB: both works find that usefulness in portfolios might differ from standalone performance
		\pause
		\vspace{\baselineskip}
		\item Instance-specific solver selection: SATzilla~\cite{xu2008satzilla, xu2012satzilla2012}, ISAC~\cite{Kadioglu:2010:ISAC}, SNNAP~\cite{Collautti:2013:SNNAP}
		%JB: also a topic outside SAT: survey and further references mentioned in our paper
		%JB: SATzilla is rather complex; besides main prediction model(s) (depending on version, solver classification or runtime regression) also pre-solvers and backup-solver
		%JB: ISAC uses clustering, SNNAP uses nearest-neighbors approach
		% JB: all theses approaches have fixed portfolio, following works vary portfolio size (but domain different to ours)
		\pause
		\vspace{\baselineskip}
		\item Analyzing $k$-portfolios for Constraint Satisfaction Problems: Amadini et al.~\cite{amadini2014empirical, amadini2016extensive}
		%JB: vary k, analyze runtime and solved instances
		%JB: compare various classifiers and multiple sophisticated portfolios approaches (like SATzilla)
		%JB: one search heuristic ("local search"), no exact/random solution
		%JB: 4547 instances (International CAP Solver Competition and MiniZinc suite benchmark), 22 solver configurations (6 distinct solvers)
		%JB: results: classifier-based portfolios clearly beat single solvers, though gap to VBS; initial improvement over k, but performance might get slightly worse again if too many solvers in portfolio
		\pause
		\vspace{\baselineskip}
		\item Analyzing $k$-portfolios for anytime algorithms: Nof and Strichman~\cite{nof2020real}
		%JB: vary k, analyze two objective function (one is ours just as maximization)
		%JB: anytime: algos run for 0.1 s or 1 s (compare that to the 5000 s in SAT Competition)
		%JB: SMT solver, k-best, and greedy search (we additionally use beam width, random search, and prediction models)
		%JB: 1000 instances (generated based on a real-world allocation problem), 24 solvers
		%JB: results: greedy very close to optimum, k-best worse
	\end{itemize}
\end{frame}

\begin{frame}[t]{Solution Approaches -- Overview}
	\begin{itemize}
		\item K-Portfolio Problem with VBS selector is NP-complete and submodular~\cite{nof2020real}
		%JB: Nof and Strichman consider  maximizing quality instead of minimizing cost, but else their problem (called "K-Algorithms Max-Sum Problem") is same as ours
		%JB: while the NP-completeness sounds discouraging, the latter is encouraging for heuristics
		%JB: "submodular" means decreasing marginal utility, e.g., adding a solver to a portfolio P decreases cost at least as much as adding same solver to superset of P
		\pause
		\vspace{\baselineskip}
		\item Examples for heuristic solutions:
		\begin{itemize}
			\item K-best~\cite{nof2020real}: Sort solvers by individual performance, pick top $k$
			\pause
			\item Beam search:
			\begin{itemize}
				\item Iteratively build portfolios of size $k+1$ from portfolios of size $k$
				\item Add the solver with highest marginal contribution to current portfolio
				\item Beam width $w$: Number of portfolios retained for next iteration
				\pause
				\item Submodularity bounds quality of greedy search ($w=1$) relative to optimal solution~\cite{nemhauser1978analysis, nof2020real}
				%JB: besides submodularity, also monotonicity (i.e., adding solvers to portfolio does not make costs worse) and non-negativity required
			\end{itemize}
		\end{itemize}
		\pause
		\vspace{\baselineskip}
		\item Examples for exact solutions:
		\begin{itemize}
			\item Encoding with Satisfiability Module Theories (SMT) by Nof and Strichman~\cite{nof2020real}
			\pause
			\item Encoding as integer linear program in our experiments
			%JB: was considerably faster than SMT with Z3
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}[t]{Solution Approaches -- Integer Linear Program}
	\begin{alignat*}{4}
		\onslide<3->{
			\min_{x,y} \quad & \mathrlap{\frac{1}{|I|} \cdot \sum_{i \in I} \sum_{s \in S} c(i,s) \cdot x_{i,s}} & & \\
		}
		\onslide<2->{
			\text{s.t.}\quad & & \sum_{s \in S} y_s &\leq k \tag*{(portfolio size)} \\
			%JB: since we have a minimization problem, exactly k solvers will be picked if there are are still useful solvers (with positive marginal contribution) available
		}
		\onslide<4->{
			& \forall i\in I: & \sum_{s \in S} x_{i,s} &= 1 \tag*{(one solver per instance)} \\
			%JB: since we have a minimization problem, the fastest solver from the portfolio will be picked automatically
		}
		\onslide<5->{
			& \forall s \in S:  & \sum_{i \in I} x_{i,s}  &\leq |I| \cdot y_s \tag*{(only use solvers from portfolio)} \\
		}
		\onslide<3->{
			& \forall i \in I \text{, } \forall s \in S: & x_{i,s} &\in \{0,1\} \tag*{(solver selected for instance or not)} \\
			%JB: also allows selecting solvers not improving portfolio (all x_{i,s} == 0); however, 1) since we have a minimization problem, existing solvers with positive marginal contribution will and preferred and 2) it might be that there is no available solver improving portfolio (in particular, if portfolio quite large)
		}
		\onslide<1->{
			& \forall s \in S: & y_s &\in \{0,1\} \tag*{(solver selected or not)}
		}
	\end{alignat*}
\end{frame}

\section{Experiments}

\begin{frame}[t]{Experimental Design}
	\begin{itemize}
		\item Two datasets (from Main Tracks of recent SAT Competitions):
		\begin{enumerate}[1)]
			\item \emph{SC2020} (316 instances, 48 solvers)~\cite{balyo2020proceedings}
			\item \emph{SC2021} (325 instances, 46 solvers)~\cite{balyo2021proceedings}
			%JB: took all solvers, but removed instances not solved any of them
		\end{enumerate}
		\begin{itemize}
			\item 138 features from feature extractor of SATzilla~2012~\cite{xu2012features, xu2012satzilla2012}
			%JB: features from twelve categories, simple ones (like number of instances) to complicated ones (like variable-clause graph node degree)
			%JB: missing values due to timeouts and memouts replaced with out-of-range value
			\item Instance features and solver runtimes retrieved from GBD~\cite{iser2020collaborative}
		\end{itemize}
		\pause
		\vspace{\baselineskip}
		\item Four solution approaches:
		%JB: all of them run for both datasets and all k (from 1 to number of solvers)
		\begin{itemize}
			\item \emph{Optimal solution} via integer programming~\cite{python-mip}
			%JB: that's the exact approach, others are heuristics
			%JB: package "mip" uses the solver "COIN-OR branch-and-cut" (Cbc) internally
			%JB: Cbc was very fast, mean runtime of 15 s, max ~5 min
			%JB: other exact optimizers should yield same portfolio cost anyway
			\item \emph{Beam search} with beam width $w \in \{1, 2, 3, \dots, 10, 20, 30, \dots, 100\}$
			\item \emph{K-best}
			\item \emph{Random sampling} with 1000 repetitions
		\end{itemize}
		\pause
		\vspace{\baselineskip}
		\item Two multi-class prediction models: Random forests~\cite{breiman2001random, scikit-learn} and XGBoost~\cite{xgboost} with 100 trees each
		%JB: ensemble tree models: powerful and can learn non-linear dependencies (RFs also used in SATzilla 2012)
		%JB: in preliminary experiments, also tried other models (e.g., kNN, untuned neural network) -> worse performance
		%JB: in preliminary experiments, also regression, instance-weighted classififcation, one-vs-one classification -> worse performance
	\end{itemize}
\end{frame}

\begin{frame}[t]{Results -- Portfolio Search (VBS on Training Set)}
	\begin{figure}[htb]
		\centering
		\includegraphics[width=\textwidth]{plots/search-train-objective.pdf}
		\caption*{Training-set VBS performance for different datasets, values of $k$, and portfolio-search approaches.}
		%JB: conducted five-fold cross-validation; portfolios search and model training on training set only
		%JB: figures are average over CV folds, in case of random sampling also over sampling repetitions
		%JB: all approaches: strong decrease with k; optimal 10-portfolio only 25% (SC2020) / 17% (SC2021) worse than portfolio out of all solvers
		%JB: greedy search is beam search with k=1; already very close to optimum (though problem NP-complete; similar findings of Nof and Strichman); slight improvement by increasing w
		%JB: also looked at composition of optimal portfolio and found that usually just 1 or 2 solvers added from k to k+1, which is nice scenario for greedy search
		%JB: upper bound follows from submodularity; far away from greedy search
		%JB: k-best between greedy and random; depends on datasets to which closer; gaps widens after first few k
	\end{figure}
\end{frame}

\begin{frame}[t]{Results -- Portfolio Search (VBS on Test Set)}
	\begin{figure}[htb]
		\centering
		\includegraphics[width=\textwidth]{plots/search-test-objective.pdf}
		\caption*{Test-set VBS performance for different datasets, values of $k$, and portfolio-search approaches.}
		%JB: overall, rather similar trends as on training set
		%JB: k-best closer to greedy/optimal than on training set; there might be slight overfitting (best potrfolio on train instances not necessarily best on test instances)
	\end{figure}
\end{frame}

\begin{frame}[t]{Results -- Recommending Solvers (MCC)}
	\begin{figure}[htb]
		\centering
		\includegraphics[width=\textwidth]{plots/prediction-test-mcc.pdf}
		\caption*{Test-set prediction performance in terms of Matthews correlation coefficient (MCC)~\cite{matthews1975comparison,gorodkin2004comparing} for different datasets, values of $k$, and prediction models. Randomly sampled portfolios.}
		%JB: that's direct way of evaluating predictions; does not consider how bad wrongly recommended solver is; indirect evaluation on next slide
		%JB: MCC is suitable for imbalanced classes; is in [-1, 1]; higher is better; 0 for random guessing and constant prediction
		%JB: random sampling to have many portfolios; prediction performance for beam-search/optimal porfolios similar
		%JB: training-set MCC close to 1, as typical for unpruned tree models (overfitting)
		%JB: prediction performance not good, but better than random guessing (apparently there is some information in features)
		%JB: slightly larger MCC and clearly more variation for small k
		%JB: random forest and XGBoost similar; focus on former in the following
	\end{figure}
\end{frame}

\begin{frame}[t]{Results -- Recommending Solvers (PAR-2 Score)}
	\begin{figure}[htb]
		\centering
		\includegraphics[width=\textwidth]{plots/prediction-test-objective-beam.pdf}
		\caption*{Test-set solver performance for different datasets, values of $k$, and solver-recommendation approaches. Portfolios from \emph{beam search} with $w=100$. Random forests for predictions.}
		%JB: beam search with w=10o to predict for a bunch of good portfolios (similar resutls for optimal portfolios)
		%JB: VBS corresponds to optimal prediction
		%JB: SBS corresponds to sensible baseline (best constant prediction), though results could even be worse
		%JB: horizontal line is global SBS, "SBS" boxes are portfolio-specific
		%JB: while VBS decreases, predictions cannot leverage new solvers (decrease from k=2 to k=3 or k=4, but not beyond)
		%JB: similar findings of Amadini et al. (though they had an improvement at least for a few more k)
		%JB: at least score of predicted solver (for k > 2) better than (global, and thus also portfolio) SBS
	\end{figure}
\end{frame}

\section{Summary}

\begin{frame}[t]{Summary and Future Work}
	\begin{itemize}
		\item Evaluated solver portfolios on data from SAT Competitions 2020 and 2021
		\pause
		\item Small portfolios already show high runtime improvement
		\pause
		\item Greedy portfolio search already close to optimal portfolio
		\pause
		\item Our prediction approach does not benefit from increased portfolio size
		\pause
		\vspace{\baselineskip}
		\item Exemplary directions for future work:
		\begin{itemize}
			\item Improve prediction performance, e.g., by using new features like community-based ones~\cite{Ansotegui:2019:CommunityStructure, Li:2021:HCS}
			%JB: did not perform deep analysis of feature importance, but RF's built-in one spread over many features (no single or small set of very useful features)
			%JB: features might also be redundant (which, however, should not impact prediction performance of tree-based models negatively)
			\item Use more specialized solvers and solver configurations
			%JB: while the solvers submitted to SAT Competition's Main Track rather are general-purpose solvers
			\item Compare to sophisticated portfolio approaches like SATzilla~\cite{xu2008satzilla, xu2012satzilla2012}
			%JB: our focus was not on creating best overall portfolio approach, but analyzing portfolio construction/size, while we kept prediction approach simple
		\end{itemize}
	\end{itemize}
\end{frame}

\appendix
\beginbackup % subsequent slides do not impact overall slide count

\begin{frame}[t, allowframebreaks]{References}
	\printbibliography
\end{frame}

\backupend

\end{document}
